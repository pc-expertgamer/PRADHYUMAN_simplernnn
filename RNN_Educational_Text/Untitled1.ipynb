{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1b5fe5d-5225-41f3-b95a-a2361cefb077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Imports and path setup complete.\n",
      "Configuration constants defined.\n",
      "Data path: C:\\Users\\Pradhyuman\\RNN_Educational_Text\\datasets\\classification_data.txt\n",
      "Model save path: C:\\Users\\Pradhyuman\\RNN_Educational_Text\\models\\classification_model.keras\n",
      "--- Starting Educational Text Classification Task ---\n",
      "Attempting to load data from: C:\\Users\\Pradhyuman\\RNN_Educational_Text\\datasets\\classification_data.txt\n",
      "Successfully loaded 100 text samples.\n",
      "Starting text preprocessing for classification...\n",
      "Cleaned 100 texts.\n",
      "No tokenizer provided, fitting a new one.\n",
      "Converted texts to 100 sequences of integers.\n",
      "Padded sequences to shape: (100, 100)\n",
      "One-hot encoded labels to shape: (100, 4)\n",
      "Effective vocabulary size for model: 873\n",
      "Text preprocessing for classification complete.\n",
      "\n",
      "Splitting data into training and testing sets...\n",
      "Training samples: 80, Test samples: 20\n",
      "y_train shape: (80, 4), y_test shape: (20, 4)\n",
      "\n",
      "Building classification model...\n",
      "  Vocabulary size: 873\n",
      "  Embedding dimension: 64\n",
      "  Max sequence length: 100\n",
      "  RNN units: 64\n",
      "  Dropout rate: 0.4\n",
      "  Number of output classes: 4\n",
      "\n",
      "Compiling the model...\n",
      "\n",
      "Model Summary:\n",
      "Model: \"Simple_RNN_Text_Classifier\"\n",
      "+--------------------------------------------------------------------------+\n",
      "| Layer (type)                    | Output Shape           |       Param # |\n",
      "|---------------------------------+------------------------+---------------|\n",
      "| embedding_layer (Embedding)     | ?                      |   0 (unbuilt) |\n",
      "|---------------------------------+------------------------+---------------|\n",
      "| lstm_layer (LSTM)               | ?                      |   0 (unbuilt) |\n",
      "|---------------------------------+------------------------+---------------|\n",
      "| dropout_layer (Dropout)         | ?                      |             0 |\n",
      "|---------------------------------+------------------------+---------------|\n",
      "| output_layer (Dense)            | ?                      |   0 (unbuilt) |\n",
      "+--------------------------------------------------------------------------+\n",
      " Total params: 0 (0.00 B)\n",
      " Trainable params: 0 (0.00 B)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Classification model built and compiled successfully.\n",
      "\n",
      "Training the model...\n",
      "Epoch 1/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.2500 - loss: 1.3842\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2656 - loss: 1.3842\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m================\u001b[0m\u001b[37m====\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2539 - loss: 1.3860\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 277ms/step - accuracy: 0.2484 - loss: 1.3863 - val_accuracy: 0.4000 - val_loss: 1.3811\n",
      "Epoch 2/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5625 - loss: 1.3714\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5833 - loss: 1.3697 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5744 - loss: 1.3705\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5745 - loss: 1.3706 - val_accuracy: 0.5000 - val_loss: 1.3754\n",
      "Epoch 3/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7500 - loss: 1.3585\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7188 - loss: 1.3576 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7144 - loss: 1.3563\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7141 - loss: 1.3558 - val_accuracy: 0.4500 - val_loss: 1.3658\n",
      "Epoch 4/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6875 - loss: 1.3312\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7257 - loss: 1.3332\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7517 - loss: 1.3309\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7597 - loss: 1.3301 - val_accuracy: 0.6000 - val_loss: 1.3467\n",
      "Epoch 5/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.2935\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9444 - loss: 1.2929\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9304 - loss: 1.2848\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9274 - loss: 1.2814 - val_accuracy: 0.5500 - val_loss: 1.2980\n",
      "Epoch 6/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8125 - loss: 1.1917\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8542 - loss: 1.1963 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8356 - loss: 1.1804\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8276 - loss: 1.1731 - val_accuracy: 0.5000 - val_loss: 1.1553\n",
      "Epoch 7/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6875 - loss: 0.9539\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7118 - loss: 0.9554\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6946 - loss: 0.9481\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6872 - loss: 0.9471 - val_accuracy: 0.5500 - val_loss: 0.9565\n",
      "Epoch 8/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6250 - loss: 0.9619\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6562 - loss: 0.8698\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6812 - loss: 0.8270\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6823 - loss: 0.8194 - val_accuracy: 0.5500 - val_loss: 0.9557\n",
      "Epoch 9/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8750 - loss: 0.6505\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8750 - loss: 0.6523 \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m================\u001b[0m\u001b[37m====\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8477 - loss: 0.6544\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8484 - loss: 0.6432 - val_accuracy: 0.7000 - val_loss: 0.7979\n",
      "Epoch 10/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7500 - loss: 0.5942\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7969 - loss: 0.5849 \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m================\u001b[0m\u001b[37m====\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8307 - loss: 0.5792\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8538 - loss: 0.5619 - val_accuracy: 0.9000 - val_loss: 0.7664\n",
      "Epoch 11/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.3346\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.3362 \n",
      "\u001b[1m4/5\u001b[0m \u001b[32m================\u001b[0m\u001b[37m====\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.3314\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.3283 - val_accuracy: 0.9000 - val_loss: 0.6088\n",
      "Epoch 12/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.1788\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.1711 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1603\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.1570 - val_accuracy: 0.8500 - val_loss: 0.4765\n",
      "Epoch 13/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0694\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0680 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0701\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0749\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0758 - val_accuracy: 0.9000 - val_loss: 0.4132\n",
      "Epoch 14/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0702\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0714 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0683\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0631\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0621 - val_accuracy: 0.9000 - val_loss: 0.3638\n",
      "Epoch 15/15\n",
      "\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m====\u001b[0m\u001b[37m================\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0435\n",
      "\u001b[1m2/5\u001b[0m \u001b[32m========\u001b[0m\u001b[37m============\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0383 \n",
      "\u001b[1m3/5\u001b[0m \u001b[32m============\u001b[0m\u001b[37m========\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0360\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0338\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m====================\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 0.8000 - val_loss: 0.4711\n",
      "\n",
      "Evaluating the model on the test set...\n",
      "  Test Loss: 0.4711\n",
      "  Test Accuracy: 0.8000 (80.00%)\n",
      "\n",
      "Saving the trained model to: C:\\Users\\Pradhyuman\\RNN_Educational_Text\\models\\classification_model.keras\n",
      "  Model saved successfully.\n",
      "  Tokenizer saved successfully to: C:\\Users\\Pradhyuman\\RNN_Educational_Text\\models\\classification_tokenizer.pkl\n",
      "\n",
      "--- Demonstrating Classification on Sample Unseen Texts ---\n",
      "\n",
      "Input Text: \"Calculus is a fundamental concept in higher mathematics.\"\n",
      "  Predicted Category: English (Confidence: 0.44)\n",
      "\n",
      "Input Text: \"The water cycle describes the continuous movement of water on, above and below the surface of the Earth.\"\n",
      "  Predicted Category: History (Confidence: 0.84)\n",
      "\n",
      "Input Text: \"The Magna Carta was a charter of rights agreed to by King John of England in 1215.\"\n",
      "  Predicted Category: History (Confidence: 0.99)\n",
      "\n",
      "Input Text: \"Shakespearean sonnets are composed of 14 lines in iambic pentameter.\"\n",
      "  Predicted Category: English (Confidence: 0.56)\n",
      "\n",
      "--- Classification Task Completed ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 22:35:46.165192: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-22 22:35:49.410574: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "C:\\Users\\Pradhyuman\\anaconda3\\envs\\work\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-05-22 22:35:56.809946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-22 22:36:01.413809: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    }
   ],
   "source": [
    "!python src/classification_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96495be7-3b1d-459b-bbe1-a2e9fb834dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
